{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "324bd544-f4fc-45e3-9ad1-c933d0ce3099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ba636d75-be43-4e5e-9124-d7e6e853467d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 120 is different from 84)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 227\u001b[0m\n\u001b[0;32m    225\u001b[0m loss \u001b[38;5;241m=\u001b[39m cross_entropy(out[\u001b[38;5;241m0\u001b[39m], y_true)\n\u001b[0;32m    226\u001b[0m grad \u001b[38;5;241m=\u001b[39m cross_entropy_grad(out[\u001b[38;5;241m0\u001b[39m], y_true)\n\u001b[1;32m--> 227\u001b[0m model\u001b[38;5;241m.\u001b[39mbackward(grad)\n\u001b[0;32m    228\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m    229\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39margmax(out[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m==\u001b[39m y_true)\n",
      "Cell \u001b[1;32mIn[54], line 195\u001b[0m, in \u001b[0;36mLeNet5.backward\u001b[1;34m(self, grad)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# Vérification des dimensions\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grad\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m120\u001b[39m):\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# Si nécessaire, ajoutez une projection linéaire\u001b[39;00m\n\u001b[1;32m--> 195\u001b[0m     grad \u001b[38;5;241m=\u001b[39m grad \u001b[38;5;241m@\u001b[39m np\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;241m120\u001b[39m, \u001b[38;5;241m84\u001b[39m)  \u001b[38;5;66;03m# Transformation de (1,84) à (1,120)\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# Application de la dérivée ReLU\u001b[39;00m\n\u001b[0;32m    198\u001b[0m grad \u001b[38;5;241m=\u001b[39m relu_deriv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc6\u001b[38;5;241m.\u001b[39minput) \u001b[38;5;241m*\u001b[39m grad  \u001b[38;5;66;03m# Maintenant (1,120) * (1,120)\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 120 is different from 84)"
     ]
    }
   ],
   "source": [
    "# LeNet-5 Training sur AMHCD (Tifinagh) - NumPy uniquement\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ------------------ Fonctions de base ------------------\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_deriv(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def softmax(x):\n",
    "    x_stable = x - np.max(x)\n",
    "    e_x = np.exp(x_stable)\n",
    "    return e_x / np.sum(e_x)\n",
    "\n",
    "def cross_entropy(y_pred, y_true):\n",
    "    return -np.log(y_pred[y_true] + 1e-15)\n",
    "\n",
    "def cross_entropy_grad(y_pred, y_true):\n",
    "    grad = y_pred.copy()\n",
    "    grad[y_true] -= 1.0\n",
    "    return grad\n",
    "\n",
    "# ------------------ Chargement des données ------------------\n",
    "def load_amhcd_from_folder(base_path, img_size=(32, 32), normalize=True):\n",
    "    class_folders = sorted(\n",
    "        [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "    )\n",
    "    X, y = [], []\n",
    "    label_map = {name: idx for idx, name in enumerate(class_folders)}\n",
    "    \n",
    "    for folder_name in class_folders:\n",
    "        folder_path = os.path.join(base_path, folder_name)\n",
    "        for fname in os.listdir(folder_path):\n",
    "            if fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(folder_path, fname)\n",
    "                try:\n",
    "                    img = Image.open(img_path).convert('L').resize(img_size)\n",
    "                    img_array = np.asarray(img, dtype=np.float32)\n",
    "                    if normalize:\n",
    "                        img_array /= 255.0\n",
    "                    X.append(img_array)\n",
    "                    y.append(label_map[folder_name])\n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur avec {img_path}: {e}\")\n",
    "    return np.array(X).reshape(-1, 1, *img_size), np.array(y), label_map\n",
    "\n",
    "# ------------------ Couches ------------------\n",
    "class Conv2D:\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=5, stride=1, padding=0, lr=0.01):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.lr = lr\n",
    "        scale = np.sqrt(2. / (in_channels * kernel_size * kernel_size))\n",
    "        self.weights = np.random.randn(out_channels, in_channels, kernel_size, kernel_size) * scale\n",
    "        self.bias = np.zeros(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        B, C, H, W = x.shape\n",
    "        out_H = (H + 2*self.padding - self.kernel_size)//self.stride + 1\n",
    "        out_W = (W + 2*self.padding - self.kernel_size)//self.stride + 1\n",
    "        out = np.zeros((B, self.weights.shape[0], out_H, out_W))\n",
    "        if self.padding > 0:\n",
    "            x_padded = np.pad(x, ((0,0), (0,0), (self.padding,self.padding), (self.padding,self.padding)), mode='constant')\n",
    "        else:\n",
    "            x_padded = x\n",
    "        for b in range(B):\n",
    "            for c in range(self.weights.shape[0]):\n",
    "                for i in range(out_H):\n",
    "                    for j in range(out_W):\n",
    "                        region = x_padded[b, :, i*self.stride:i*self.stride+self.kernel_size, j*self.stride:j*self.stride+self.kernel_size]\n",
    "                        out[b, c, i, j] = np.sum(region * self.weights[c]) + self.bias[c]\n",
    "        return out\n",
    "\n",
    "class AveragePooling2D:\n",
    "    def __init__(self, size=2, stride=2):\n",
    "        self.size = size\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        B, C, H, W = x.shape\n",
    "        out_H = (H - self.size) // self.stride + 1\n",
    "        out_W = (W - self.size) // self.stride + 1\n",
    "        out = np.zeros((B, C, out_H, out_W))\n",
    "        for b in range(B):\n",
    "            for c in range(C):\n",
    "                for i in range(out_H):\n",
    "                    for j in range(out_W):\n",
    "                        region = x[b, c, i*self.stride:i*self.stride+self.size, j*self.stride:j*self.stride+self.size]\n",
    "                        out[b, c, i, j] = np.mean(region)\n",
    "        return out\n",
    "\n",
    "    def backward(self, grad_out):\n",
    "        B, C, H, W = self.input.shape\n",
    "        dx = np.zeros_like(self.input)\n",
    "        out_H, out_W = grad_out.shape[2:]\n",
    "        for b in range(B):\n",
    "            for c in range(C):\n",
    "                for i in range(out_H):\n",
    "                    for j in range(out_W):\n",
    "                        dx[b, c, i*self.stride:i*self.stride+self.size, j*self.stride:j*self.stride+self.size] += grad_out[b, c, i, j] / (self.size**2)\n",
    "        return dx\n",
    "\n",
    "class Dense:\n",
    "    def __init__(self, in_features, out_features, lr=0.01):\n",
    "        scale = np.sqrt(2.0 / in_features)\n",
    "        self.W = np.random.randn(in_features, out_features) * scale\n",
    "        self.b = np.zeros(out_features)\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        return np.dot(x, self.W) + self.b\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "    # S’assurer que tout est 2D\n",
    "        if grad_output.ndim == 1:\n",
    "            grad_output = grad_output[np.newaxis, :]  # (1, out)\n",
    "        if self.input.ndim == 1:\n",
    "            input_reshaped = self.input[np.newaxis, :]  # (1, in)\n",
    "        else:\n",
    "            input_reshaped = self.input\n",
    "\n",
    "        grad_input = np.dot(grad_output, self.W.T)\n",
    "        grad_W = np.dot(input_reshaped.T, grad_output)\n",
    "        grad_b = np.sum(grad_output, axis=0)\n",
    "\n",
    "        self.W -= self.lr * grad_W\n",
    "        self.b -= self.lr * grad_b\n",
    "\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "# ------------------ LeNet-5 ------------------\n",
    "class LeNet5:\n",
    "    def __init__(self, lr=0.001, num_classes=23):\n",
    "        self.lr = lr\n",
    "        self.c1 = Conv2D(1, 6, 5, lr=lr)\n",
    "        self.s2 = AveragePooling2D(2, 2)\n",
    "        self.c3 = Conv2D(6, 16, 5, lr=lr)\n",
    "        self.s4 = AveragePooling2D(2, 2)\n",
    "        self.fc5 = Dense(16*5*5, 120, lr)\n",
    "        self.fc6 = Dense(120, 84, lr)\n",
    "        self.fc7 = Dense(84, num_classes, lr)\n",
    "    def forward(self, x):\n",
    "        self.x1 = self.c1.forward(x)\n",
    "        self.conv1_feature = self.x1.copy()\n",
    "        self.x2 = relu(self.x1)\n",
    "        self.x3 = self.s2.forward(self.x2)\n",
    "        self.x4 = self.c3.forward(self.x3)\n",
    "        self.x5 = relu(self.x4)\n",
    "        self.x6 = self.s4.forward(self.x5)\n",
    "        self.x7 = self.x6.reshape(self.x6.shape[0], -1)\n",
    "        self.x8 = self.fc5.forward(self.x7)\n",
    "        self.x9 = relu(self.x8)\n",
    "        self.x10 = self.fc6.forward(self.x9)\n",
    "        self.x11 = relu(self.x10)\n",
    "        self.x12 = self.fc7.forward(self.x11)\n",
    "        return softmax(self.x12)\n",
    "\n",
    "    def backward(self, grad):\n",
    "        grad = self.fc7.backward(grad)\n",
    "        grad = relu_deriv(self.x10) * grad\n",
    "        grad = self.fc6.backward(grad)\n",
    "        grad = relu_deriv(self.x8) * grad\n",
    "        grad = self.fc5.backward(grad)\n",
    "        grad = grad.reshape(-1, 16, 5, 5)\n",
    "        grad = self.s4.backward(grad)\n",
    "        grad = relu_deriv(self.x4) * grad\n",
    "        grad = self.c3.backward(grad)\n",
    "        grad = self.s2.backward(grad)\n",
    "        grad = relu_deriv(self.x1) * grad\n",
    "        self.c1.backward(grad)\n",
    "\n",
    "    def backward(self, grad):\n",
    "    \n",
    "        # Passe arrière à travers fc7\n",
    "        grad = self.fc7.backward(grad)  # Doit retourner (1,84)\n",
    "    \n",
    "        # Vérification des dimensions\n",
    "        if grad.shape != (1, 120):\n",
    "            # Si nécessaire, ajoutez une projection linéaire\n",
    "            grad = grad @ np.eye(120, 84)  # Transformation de (1,84) à (1,120)\n",
    "    \n",
    "        # Application de la dérivée ReLU\n",
    "        grad = relu_deriv(self.fc6.input) * grad  # Maintenant (1,120) * (1,120)\n",
    "    \n",
    "        # Passe arrière à travers fc6\n",
    "        grad = self.fc6.backward(grad)\n",
    "    \n",
    "        # Continuez avec les autres couches...\n",
    "        grad = relu_deriv(self.fc5.input) * grad\n",
    "        grad = self.fc5.backward(grad)\n",
    "    \n",
    "        return grad\n",
    "\n",
    "\n",
    "# ------------------ Entraînement ------------------\n",
    "data_dir = \"amhcd-data-64/tifinagh-images\"\n",
    "X, y, label_map = load_amhcd_from_folder(data_dir)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "model = LeNet5(lr=0.001)\n",
    "n_epochs = 10\n",
    "train_losses, train_accs, val_accs = [], [], []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    for x, y_true in zip(X_train, y_train):\n",
    "        x = x[np.newaxis, :, :, :]\n",
    "        out = model.forward(x)\n",
    "        loss = cross_entropy(out[0], y_true)\n",
    "        grad = cross_entropy_grad(out[0], y_true)\n",
    "        model.backward(grad)\n",
    "        epoch_loss += loss\n",
    "        correct += (np.argmax(out[0]) == y_true)\n",
    "\n",
    "    train_loss = epoch_loss / len(X_train)\n",
    "    train_acc = correct / len(X_train)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    val_correct = 0\n",
    "    y_preds, y_trues = [], []\n",
    "    for x, y_true in zip(X_val, y_val):\n",
    "        x = x[np.newaxis, :, :, :]\n",
    "        out = model.forward(x)\n",
    "        pred = np.argmax(out[0])\n",
    "        y_preds.append(pred)\n",
    "        y_trues.append(y_true)\n",
    "        val_correct += (pred == y_true)\n",
    "    val_acc = val_correct / len(X_val)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2%} | Val Acc: {val_acc:.2%}\")\n",
    "\n",
    "# ------------------ Visualisation ------------------\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accs, label='Train Acc')\n",
    "plt.plot(val_accs, label='Val Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "cm = confusion_matrix(y_trues, y_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "features = model.conv1_feature[0]\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(features[i], cmap='gray')\n",
    "    plt.title(f'Feature Map {i+1}')\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Feature Maps from First Conv Layer')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292b79ac-1fd3-468c-9e13-d80102781594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
